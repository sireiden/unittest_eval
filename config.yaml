models:
  - "gemma2:2b"
  - "granite-code:3b"
  - "qwen2.5-coder:3b"
  - "llama3.2:3b"

temperature: 0.2
max_length: 512

source_files:
  - "src/simple.py"
  - "src/intermediate.py"
  - "src/advanced.py"

evaluation:
  coverage_threshold: 50

strategy:
  - "Few-Shot"
  - "Chain of Thought"
  - "Self Consistency"

prompts:
  - name: "Assert-Based Self-Consistency"
    instruction: |
      Apply the self-consistency prompt engineering strategy by generating multiple candidate tests that use straightforward asserts in your test functions. Then, synthesize a final, most comprehensive test suite that covers all major functionalities in <<CODE>>.

  - name: "Edge Cases Exploration"
    instruction: |
      Use the self-consistency method to propose multiple unusual or extreme inputs for <<CODE>>, then converge on a suite of pytest cases that thoroughly tests edge behavior and corner cases.

  - name: "Parameter Variations and Boundaries"
    instruction: |
      Enumerate different parameter values and boundary conditions for each function in <<CODE>> using the self-consistency approach. Compare these tests and unify them into a final suite that maximizes coverage of input ranges.

  - name: "Refactor and Compare"
    instruction: |
      Generate potential refactor-based tests for <<CODE>> by analyzing potential refactoring pathways. Use self-consistency to unify these different test versions into a single, refined test suite ensuring code stability after refactors.

  - name: "Mutation Testing Perspective"
    instruction: |
      Envision how mutation testing might alter <<CODE>>. Generate multiple test sets designed to catch these mutations using a self-consistency approach. Merge the best ideas into a single robust test suite.

  - name: "Pairwise Combinatorial Approach"
    instruction: |
      Use self-consistency to generate pairwise input combinations for each function in <<CODE>>. Compare multiple sets of pairwise tests and converge on the highest coverage suite for pytest.

  - name: "Property-Based Testing"
    instruction: |
      Brainstorm multiple property-based (Hypothesis) tests for each function in <<CODE>> using the self-consistency strategy. Evaluate each candidate test set for coverage and combine them into a final, refined suite.

  - name: "Performance and Stress Tests"
    instruction: |
      Propose several approaches for performance and stress tests on <<CODE>>. Utilize self-consistency to compare these approaches and unify them into a final, robust performance-testing suite for pytest.

  - name: "Exception Handling and Fault Injection"
    instruction: |
      Generate test scenarios that deliberately trigger errors and exceptions in <<CODE>>. Through self-consistency, select the most effective scenarios to ensure all exception paths are covered by pytest.

  - name: "Mock and Patch Strategies"
    instruction: |
      Brainstorm various ways to mock or patch dependencies within <<CODE>> using the self-consistency approach. Compare your mock testing approaches and synthesize a final, optimal set of unit tests.

  - name: "Test-Driven Development (TDD) Simulation"
    instruction: |
      Pretend to follow a TDD workflow for the functionalities in <<CODE>>. Use self-consistency to propose incremental test sets, merging them into a final high-coverage pytest suite that evolves as the code is built.

  - name: "Behavior-Driven Testing"
    instruction: |
      Devise multiple scenarios capturing user stories for <<CODE>>. Using self-consistency, refine these BDD-style tests and finalize a comprehensive suite of given-when-then tests.

  - name: "Data-Driven Test Generation"
    instruction: |
      Propose various data-driven tests for <<CODE>>, each with different datasets or configurations. Apply self-consistency to select the most relevant combinations that thoroughly test functionality.

  - name: "Regression Test Coverage"
    instruction: |
      Imagine multiple regression scenarios for <<CODE>> that might be affected by updates. Use self-consistency to consolidate these regression tests into a thorough test suite that prevents old bugs from reoccurring.

  - name: "Integration and Workflow Coverage"
    instruction: |
      Brainstorm multiple ways the components in <<CODE>> might integrate. Using self-consistency, unify these integration test ideas to ensure the entire workflow is verified in pytest.

  - name: "Functional vs. Structural"
    instruction: |
      Generate sets of tests focusing on functional coverage, then propose structural (code-level) coverage tests for <<CODE>>. Apply self-consistency to merge these into one unified suite maximizing coverage.

  - name: "Scenario-Based Testing"
    instruction: |
      Devise multiple real-world scenarios to test <<CODE>>. Through self-consistency, refine and converge on the final scenario-based suite that ensures every pathway is tested.

  - name: "Hybrid Testing with Randomized Inputs"
    instruction: |
      Create candidate strategies blending standard unit tests with random input generation for <<CODE>>. Use self-consistency to resolve conflicting test designs into a single, thorough suite.

  - name: "Incremental Complexity"
    instruction: |
      Generate tests incrementally, starting from the simplest possible inputs up to very complex ones for <<CODE>>. Utilize self-consistency to merge these incremental ideas into a final, comprehensive test suite.

  - name: "Validation and Verification of Assumptions"
    instruction: |
      List multiple assumptions the code in <<CODE>> might rely on. Propose tests for each assumption using the self-consistency strategy, then finalize a pytest suite ensuring all assumptions are valid and verified.
